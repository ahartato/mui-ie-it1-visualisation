{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ca83df-db31-4222-b153-a651a9e13c21",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57672f62-d780-415a-b915-c7b88f51c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df585a-46e3-47d5-821e-6fc50c64d0cc",
   "metadata": {},
   "source": [
    "## 2. NLTK Resource Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52d9122-e9a2-47cc-a3d4-c0498e7e54b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Aditya/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Aditya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/Aditya/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentimental analysis\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Tokeniser\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848070f-0a5c-4ecd-ba7d-72ee74bb5486",
   "metadata": {},
   "source": [
    "## 2. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6844e822-0fad-4b93-88ff-586498dfce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter data\n",
    "tweets_df = pd.read_csv(\"datasets/cyberbullying_tweets.csv\")\n",
    "\n",
    "# text msg data\n",
    "aggro_mendeley_df = pd.read_csv(\"datasets/aggressive_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bdc6c5-9c32-4201-ba0f-3179a030e351",
   "metadata": {},
   "source": [
    "## 3. Extract cyberbullying texts from raw dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b154331-0d57-4011-b4a8-6bd3fadf91a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['No.', 'Message'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "aggro_tweets_df = tweets_df[tweets_df['cyberbullying_type'] != 'not_cyberbullying']\n",
    "\n",
    "print(aggro_mendeley_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2c877-4189-428c-904a-aedb3caaf259",
   "metadata": {},
   "source": [
    "## 4. Extract texts from each dataframe and combine to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aadc3269-e300-4667-a9e6-8f04be970014",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mendeley_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract toxic messages from both datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m aggro_mendeley_texts \u001b[38;5;241m=\u001b[39m mendeley_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMessage\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# From Mendeley dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m aggro_tweet_texts \u001b[38;5;241m=\u001b[39m aggro_tweets_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]           \u001b[38;5;66;03m# From filtered Twitter dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Combine into a single Series\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mendeley_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract toxic messages from both datasets\n",
    "aggro_mendeley_texts = aggro_mendeley_df['Message']  # From Mendeley dataset\n",
    "aggro_tweet_texts = aggro_tweets_df['tweet_text']           # From filtered Twitter dataset\n",
    "\n",
    "# Combine into a single Series\n",
    "combined_aggro_texts = pd.concat([aggro_tweet_texts, aggro_mendeley_texts], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54ff2df-1233-4e32-876f-6a74c14a935f",
   "metadata": {},
   "source": [
    "## 5. Create function to clean and tokenise text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab349488-53e5-4eeb-9963-a092ba67a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_and_tokenise(text):\n",
    "    \"\"\"\n",
    "    Input: Social Media Text (Series)\n",
    "    Output: Tokens (Series)\n",
    "    This function converts text into lower case, removes URLs, mentions, \n",
    "    hastags, numbers, non-letters, and stopwords and outputs tokens.\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs, mentions, hashtags, numbers, and non-letters\n",
    "    text = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+|\\d+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    \n",
    "    # Tokenise\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and short words\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 1]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630b2c1-e56f-4c91-84fd-17d4349a45d5",
   "metadata": {},
   "source": [
    "## 6. Clean and tokenise text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f275b1-31cf-4c62-8984-e2c814bdcfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all entries are string type (and handle NaNs)\n",
    "combined_aggro_texts = combined_aggro_texts.fillna(\"\").astype(str)\n",
    "\n",
    "# Apply to all toxic messages\n",
    "combined_tokens = combined_aggro_texts.apply(clean_and_tokenise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306bb29-1534-4ffc-8961-6275ed2b727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example preview\n",
    "print(combined_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a731dd5a-66e1-43b8-8bee-65562d45d908",
   "metadata": {},
   "source": [
    "## 7. Extract tokens with low sentiment analysis scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643def35-7dc5-4515-a9e5-070c53034e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Flatten all tokens into one list\n",
    "all_tokens = [word for tokens in combined_tokens for word in tokens]\n",
    "\n",
    "# Compute sentiment scores\n",
    "word_sentiments = {word: sia.polarity_scores(word)['compound'] for word in set(all_tokens)}\n",
    "\n",
    "# Filter words with strongly negative sentiment (e.g., score < -0.5)\n",
    "# toxic_words_via_sentiment = [word for word in all_tokens if word_sentiments.get(word, 0) < 0]\n",
    "\n",
    "toxic_words_via_sentiment = [\n",
    "    word for word in all_tokens \n",
    "    if -0.45 < word_sentiments.get(word, 0) < -0.25\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d6738-edfc-4b1e-8886-def19d3f3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequency\n",
    "toxic_word_freq = Counter(toxic_words_via_sentiment)\n",
    "\n",
    "# Preview top toxic words by sentiment\n",
    "print(toxic_word_freq.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88f409-457d-4917-9867-1cc27a187baf",
   "metadata": {},
   "source": [
    "## 8. Export the most frequent toxic words as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521e43b-25a4-4dd9-8f31-edf13215507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top 1000 most frequent toxic words\n",
    "top_toxic = toxic_word_freq.most_common(1000)\n",
    "\n",
    "# Convert to DataFrame\n",
    "top_toxic_df = pd.DataFrame(top_toxic, columns=['word', 'frequency'])\n",
    "\n",
    "# Preview\n",
    "print(top_toxic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cba2e0-f967-44ff-8eeb-6c50e3441810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv\n",
    "top_toxic_df.to_csv(\"top_toxic_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7b06e-824b-4300-a494-e57b40db73f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
